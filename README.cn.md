# Offline AI PPE CLI(WIP)

> ã€[English](./README.md)|ä¸­æ–‡ã€‘
---
[å¯ç¼–ç¨‹æç¤ºå¼•æ“](https://github.com/offline-ai/ppe)çš„æ™ºèƒ½ä½“è„šæœ¬å®¢æˆ·ç«¯

[![oclif](https://img.shields.io/badge/cli-oclif-brightgreen.svg)](https://oclif.io)
[![Version](https://img.shields.io/npm/v/%40offline-ai%2Fcli.svg)](https://npmjs.org/package/@offline-ai/cli)
[![Downloads/week](https://img.shields.io/npm/dw/%40offline-ai%2Fcli.svg)](https://npmjs.org/package/@offline-ai/cli)

è§‰å¾—è¿™ä¸ªé¡¹ç›®ä¸é”™ï¼Ÿè¯·ç”¨ç‚¹æ˜Ÿæ¥è¡¨ç¤ºæ‚¨çš„æ”¯æŒï¼ğŸŒŸ

AI Agent è„šæœ¬å¼•æ“ç‰¹ç‚¹:

* å¯ç¼–ç¨‹æç¤ºè¯å·¥ç¨‹ (PPE) è¯­è¨€æ˜¯ä¸€ç§ç®€å•ä¸”è‡ªç„¶çš„è„šæœ¬è¯­è¨€ï¼Œä¸“é—¨ç”¨äºå¤„ç†æç¤ºè¯ä¿¡æ¯ã€‚è¿™ç§è¯­è¨€ç”¨äºå¼€å‘å„ç§æ™ºèƒ½ä½“ï¼Œè¿™äº›æ™ºèƒ½ä½“å¯ä»¥è¢«é‡ç”¨ã€ç»§æ‰¿ã€ç»„åˆæˆ–è°ƒç”¨ã€‚
* è®©ä¸­å°è§„æ¨¡(35B-4B)çš„å¼€æºLLMå¤§æ¨¡å‹èƒ½å¤Ÿè¾¾åˆ°æˆ–è¿‘ä¼¼ChatGPT4å¤§æ¨¡å‹çš„æ•ˆæœ...
* ç®€å•,æ–¹ä¾¿æ™ºèƒ½ä½“å¼€å‘,åˆ›å»ºæ™ºèƒ½åº”ç”¨...
* ä½ä»£ç ,å°‘é‡ä»£ç ,ç”šè‡³æ— ä»£ç å°±èƒ½å¿«é€Ÿå¼€å‘...
* çµæ´»,å¯ä»¥åœ¨è„šæœ¬ä¸­è‡ªç”±æ·»åŠ æ–°çš„æŒ‡ä»¤,è„šæœ¬ä¹‹é—´å¯ä»¥è‡ªç”±è°ƒç”¨...
* æ•°æ®å¼€æ”¾,åœ¨è„šæœ¬ä¸­å¯ä»¥è‡ªç”±è®¿é—®è¾“å…¥è¾“å‡ºæ•°æ®,ä»¥åŠå†…éƒ¨æ•°æ®...
* å¼ºå¤§,äº‹ä»¶èƒ½å¤Ÿåœ¨å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ç«¯æ— æ„Ÿè‡ªç”±ä¼ é€’,è¯¸å¤šå·¥å…·å‡½æ•°...
* å®‰å…¨,è„šæœ¬æ”¯æŒåŠ å¯†æ‰§è¡Œ,è¯•ç”¨æ¬¡æ•°é™åˆ¶(TODO)...
* è®©æœ¬æœºè¿è¡Œ LLM å¤§æ¨¡å‹, å¹¶ä¸”æ”¯æŒæœ¬åœ°éƒ¨ç½² LLM å¤§æ¨¡å‹ï¼ˆLLaMA, Qwen, Gemma, Phi, GLM, Mistral, ...ï¼‰
* æ™ºèƒ½ä½“è„šæœ¬éµå¾ª[å¯ç¼–ç¨‹æç¤ºè¯å·¥ç¨‹è§„èŒƒ](https://github.com/offline-ai/ppe/blob/main/README.cn.md)
  * è®¿é—®è¯¥ç«™ç‚¹æŸ¥çœ‹è¯¦ç»†è„šæœ¬çš„ç”¨æ³•
* [å¯ç¼–ç¨‹æç¤ºè¯å·¥ç¨‹æµ‹è¯•ç”¨ä¾‹å•å…ƒæµ‹è¯•](https://github.com/offline-ai/cli-plugin-cmd-test.js)
  * Fixtures Demo: https://github.com/offline-ai/cli/tree/main/examples/split-text-paragraphs
* æ™ºèƒ½ç¼“å­˜LLMå¤§æ¨¡å‹ä»¥åŠæ™ºèƒ½ä½“è°ƒç”¨ç»“æœï¼ŒåŠ é€Ÿè¿è¡Œä»¥åŠå‡å°‘tokenså¼€é”€
* æ”¯æŒå¤šLLMæœåŠ¡æä¾›å•†ï¼š
  * ï¼ˆ**æ¨è**ï¼‰**å†…ç½®æœ¬åœ°LLMæä¾›å•†ï¼ˆllama.cppï¼‰**ä½œä¸ºé»˜è®¤é€‰é¡¹ï¼Œä»¥ä¿æŠ¤çŸ¥è¯†çš„å®‰å…¨æ€§å’Œéšç§ã€‚
    * é¦–å…ˆä¸‹è½½GGUFæ¨¡å‹æ–‡ä»¶ï¼š`ai brain download hf://bartowski/Qwen_QwQ-32B-GGUF -q q4_0`
    * ä½¿ç”¨é»˜è®¤çš„å¤§è„‘æ¨¡å‹æ–‡ä»¶è¿è¡Œï¼š`ai run example.ai.yaml`
    * ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶è¿è¡Œï¼š`ai run example.ai.yaml -P local://bartowski-qwq-32b.Q4_0.gguf`
  * å…¼å®¹OpenAIçš„æœåŠ¡æä¾›å•†ï¼š
    * OpenAI: `ai run example.ai.yaml -P openai://chatgpt-4o-latest --apiKey â€œsk-XXXâ€`
    * DeepSeek: `ai run example.ai.yaml -P openai://deepseek-chat -u https://api.deepseek.com/ --apiKey â€œsk-XXXâ€`
    * Siliconflow: `ai run example.ai.yaml -P openai://Qwen/Qwen2.5-Coder-7B-Instruct -u https://api.siliconflow.cn/ --apiKey â€œsk-XXXâ€`
    * Anthropic(Claude): `ai run example.ai.yaml -P openai://claude-3-7-sonnet-latest -u https://api.anthropic.com/v1/ --apiKey â€œsk-XXXâ€`
  * [llama-cppæœåŠ¡å™¨(llama-server)æä¾›å•†](https://github.com/ggml-org/llama.cpp/tree/master/examples/server)ï¼š`ai run example.ai.yaml -P llamacpp`
    * llama-cppæœåŠ¡å™¨ä¸æ”¯æŒæŒ‡å®šæ¨¡å‹åç§°ï¼Œå®ƒæ˜¯åœ¨å¯åŠ¨llama-serveræ—¶é€šè¿‡ model å‚æ•°æŒ‡å®šçš„ã€‚
  * æ‚¨å¯ä»¥åœ¨PPEè„šæœ¬ä¸­æŒ‡å®šæˆ–ä»»æ„åˆ‡æ¢*LLMæ¨¡å‹æˆ–æä¾›å•†*:

  ```yaml
  ---
  parameters:
    model: openai://deepseek-chat
    apiUrl: https://api.deepseek.com/
    apiKey: "sk-XXX"
  ---
  system: You are a helpful assistant.
  user: "tell me a joke"
  --- # first dialog begin
  assistant: "[[AI]]"
  --- # reset to first
  assistant: "[[AI:model='openai://claude-3-7-sonnet-latest',apiUrl='https://api.anthropic.com/v1/',apiKey='sk-XXX']]"
  --- # reset to first
  assistant: "[[AI:model='local://bartowski-qwq-32b.Q4_0.gguf']]"
  ```

* **å†…ç½®æœ¬åœ°LLMæä¾›å•†(llama.cpp)** åŠŸèƒ½ç‰¹æ€§
  * é»˜è®¤è‡ªåŠ¨æ£€æµ‹å†…å­˜å’ŒGPUï¼Œå¹¶é»˜è®¤ä½¿ç”¨æœ€ä½³è®¡ç®—å±‚ï¼Œè‡ªåŠ¨åˆ†é…gpu-layersä»¥åŠä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆä¼šé‡‡ç”¨å°½å¯èƒ½å¤§çš„å€¼ï¼‰ï¼Œä»¥ä¾¿ä»ç¡¬ä»¶ä¸­è·å¾—æœ€ä½³æ€§èƒ½ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ä»»ä½•å†…å®¹ã€‚
    * å»ºè®®ä¸Šä¸‹æ–‡çª—å£è‡ªè¡Œé…ç½®
  * ç³»ç»Ÿå®‰å…¨:ç³»ç»Ÿæ¨¡æ¿åæ³¨å…¥ï¼ˆé¿å…è¶Šç‹±ï¼‰æ”¯æŒ
  * ä»»æ„å¤§æ¨¡å‹é€šç”¨å·¥å…·è°ƒç”¨ï¼ˆTool Funcsï¼‰æ”¯æŒ
    * æ— éœ€å¤§æ¨¡å‹ä¸“é—¨è®­ç»ƒå³å¯æ”¯æŒï¼Œè¦æ±‚å¤§æ¨¡å‹æŒ‡ä»¤éµå¾ªèƒ½åŠ›å¼º
    * æœ€å°é€‚é…3Bæ¨¡å‹ï¼Œæ¨èä½¿ç”¨7BåŠä»¥ä¸Š
    * åŒé‡æƒé™æ§åˆ¶:
      1. è„šæœ¬è®¾å®šAIèƒ½å¤Ÿä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
      2. ç”¨æˆ·è®¾å®šè„šæœ¬èƒ½ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
  * ä»»æ„å¤§æ¨¡å‹é€šç”¨æ€ç»´æ¨¡å¼ï¼ˆ`shouldThink`ï¼‰æ”¯æŒ
    * æ— éœ€å¤§æ¨¡å‹ä¸“é—¨è®­ç»ƒå³å¯æ”¯æŒï¼Œè¦æ±‚å¤§æ¨¡å‹æŒ‡ä»¤éµå¾ªèƒ½åŠ›å¼º
    * æœ€å°é€‚é…3Bæ¨¡å‹ï¼Œæ¨èä½¿ç”¨7BåŠä»¥ä¸Š
    * å…ˆå›ç­”å†æ€è€ƒï¼ˆ`last`ï¼‰
    * å…ˆæ€è€ƒå†å›ç­”(`first`)
    * æ·±åº¦æ€è€ƒåå†å›ç­”ï¼ˆ`deep`ï¼‰: 7BåŠä»¥ä¸Š
* Package æ”¯æŒ
* PPEæ”¯æŒç›´æ¥è°ƒç”¨ wasm
* å¤šç§ç»“æ„åŒ–å“åº”è¾“å‡ºæ ¼å¼ç±»å‹(`response_format.type`)æ”¯æŒ:
  * JSON æ ¼å¼
  * YAML æ ¼å¼
  * è‡ªç„¶è¯­è¨€å¯¹è±¡(NOBJ) æ ¼å¼
  * ç”¨JSON Schemaæ ¼å¼è®¾ç½®å¥½`output`.PPEå°±ä¼šè‡ªåŠ¨è§£æAIç”Ÿæˆçš„å¯¹åº”æ ¼å¼çš„å†…å®¹ä¸º`Object`ä¾›ä»£ç ä½¿ç”¨.

ä½¿ç”¨AI Agent è„šæœ¬å¼•æ“å¼€å‘ä¸€ä¸ªæ™ºèƒ½åº”ç”¨åªéœ€è¦ä¸‰æ­¥:

1. é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„è„‘å­ğŸ§ (LLMå¤§æ¨¡å‹)
   1. å‚æ•°è§„æ¨¡çš„é€‰æ‹©,æ ¹æ®è‡ªå·±åº”ç”¨çš„éœ€æ±‚å†³å®š,å‚æ•°è§„æ¨¡è¶Šå¤§,è¾“å‡ºè´¨é‡è¶Šé«˜,ä½†æ˜¯ä¹Ÿä¼šæ¶ˆè€—æ›´å¤šèµ„æº...å“åº”æ—¶é—´ä¹Ÿä¼šå˜é•¿...
   2. ç‰¹é•¿çš„é€‰æ‹©,ä¸åŒçš„è„‘å­è®­ç»ƒçš„æ–¹å¼ä¸åŒ,è®­ç»ƒçš„ç´ æ(dataset)ä¸åŒ,ç‰¹é•¿ä¹Ÿä¸åŒ...
   3. é€‰æ‹©åˆé€‚çš„é‡åŒ–ç¨‹åº¦,é‡åŒ–(å‹ç¼©)ç¨‹åº¦è¶Šå¤§,é€Ÿåº¦è¶Šå¿«,ä½“ç§¯è¶Šå°,ç²¾åº¦è¶Šå·®...
   4. é€‰æ‹©åˆé€‚çš„æœ€å¤§çª—å£æ­£æ–‡é•¿åº¦(`content_size`), ä¸€èˆ¬ 2048 è¶³å¤Ÿ, è¿™ä¸ªå‚æ•°ä¹Ÿä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½...
   5. ç„¶åç›´æ¥ä½¿ç”¨å®¢æˆ·ç«¯(`@offline-ai/cli`)ä¸‹è½½: `ai brain download`
2. åˆ›å»ºåº”ç”¨çš„æ™ºèƒ½ä½“è„šæœ¬æ–‡ä»¶,ä½¿ç”¨å®¢æˆ·ç«¯(`@offline-ai/cli`)è°ƒè¯•æ™ºèƒ½ä½“æç¤ºè¯: `ai run your_script.ai.yaml --interactive --loglevel info`.
3. åµŒå…¥åˆ°è‡ªå·±çš„æ™ºèƒ½åº”ç”¨ä¸­
4. ä¸€é”®æ‰“åŒ…ç”Ÿæˆç‹¬ç«‹çš„æ™ºèƒ½åº”ç”¨(TODO)

## Quick Start

* [å¿«é€Ÿä¸Šæ‰‹ç¼–ç¨‹å€¼å—](./guide-cn.md)
* æ›´å¤šçš„ä¾‹å­: [examples](./examples)
* ä½¿ç”¨ PPE Language ç¼–å†™çš„ AI åº”ç”¨ç¨‹åºï¼š
  * [PPE çš„ æ™ºèƒ½ç¼–ç¨‹æŒ‡å—](./lib/guide/)
    * åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œ `ai run guide` æ¥å¯åŠ¨æŒ‡å—
  * [äººå·¥æ™ºèƒ½ç»ˆç«¯ shell](https://github.com/offline-ai/ai-shell)
* LLM æ¨ç†æä¾›è€…:
  * `llamacpp`: llama.cpp server ä½œä¸ºé»˜è®¤çš„æœ¬åœ° LLM æä¾›è€…. å¦‚æœæ²¡æœ‰æä¾›`provider`,å°±æ˜¯`llamacpp`
  * `openai`: ä¹Ÿæ”¯æŒ OpenAIå…¼å®¹ æœåŠ¡ API æä¾›è€….
    * `--provider openai://chatgpt-4o-latest --apiKey â€œsk-XXXâ€`

æ³¨æ„: OpenAIå…¼å®¹ æœåŠ¡ API æä¾›è€…çš„é™åˆ¶

1. OpenAI å¿…é¡»æ˜¯`gpt-4o` `2024-07-18`ä¹‹åçš„å¤§æ¨¡å‹æ‰æ”¯æŒï¼ˆjson-schemaï¼‰ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œä»…èƒ½ä¿è¯ `json` æ”¯æŒï¼Œæ— æ³•ä¿è¯schema.
2. `siliconflow` çš„æ‰€æœ‰æ¨¡å‹åªä¿è¯json,ä¸ä¿è¯schema.
   * `--provider openai://Qwen/Qwen2.5-Coder-7B-Instruct -u https://api.siliconflow.cn/ --apiKey â€œsk-XXXâ€ ...`
3. `[[Fruit:|Apple|Banana]]`: è®©AIå¼ºåˆ¶å•é€‰æˆ–å¤šé€‰è¯­æ³•ï¼Œå°†å¤±æ•ˆ

## [Programmable Prompt Engine Language](./lib/guide/lang.md)

å¯ç¼–ç¨‹æç¤ºå¼•æ“ (PPE) è¯­è¨€æ˜¯ä¸€ç§æ¶ˆæ¯å¤„ç†è¯­è¨€ï¼Œç±»ä¼¼äº YAML æ ¼å¼ã€‚

PPE è®¾è®¡ç”¨äºå®šä¹‰ AI æç¤ºæ¶ˆæ¯åŠå…¶è¾“å…¥/è¾“å‡ºé…ç½®ã€‚å®ƒå…è®¸åˆ›å»ºä¸€ä¸ªå¯é‡ç”¨ä¸”å¯ç¼–ç¨‹çš„æç¤ºç³»ç»Ÿï¼Œç±»ä¼¼äºè½¯ä»¶å·¥ç¨‹å®è·µã€‚

### [I. æ ¸å¿ƒç»“æ„](./lib/guide/core-lang.md)

* **åŸºäºæ¶ˆæ¯çš„å¯¹è¯**ï¼šå°†äº¤äº’å®šä¹‰ä¸ºä¸€ç³»åˆ—å¸¦æœ‰è§’è‰²ï¼ˆç³»ç»Ÿ(system)ã€ç”¨æˆ·(user)ã€åŠ©æ‰‹(assistant)ï¼‰çš„æ¶ˆæ¯ã€‚
* **ç±»ä¼¼ YAML çš„è¯­æ³•**ï¼šè¯­æ³•ç±»ä¼¼äº YAMLï¼Œä½¿å…¶æ˜“äºé˜…è¯»å’Œç†è§£ã€‚
* **å¯¹è¯åˆ†éš”**: ä½¿ç”¨ä¸‰ä¸ªå‡å· (`---`) æˆ–æ˜Ÿå· (`***`) æ¸…æ¥šåœ°æ ‡è®°å¯¹è¯è½®æ¬¡ã€‚

### [II. å¯é‡ç”¨æ€§å’Œé…ç½®](./lib/guide/lang-reuse.md)

* **Input/Output é…ç½® (Front-Matter)**: ä½¿ç”¨ `input` å…³é”®å­—å®šä¹‰è¾“å…¥è¦æ±‚ï¼Œä½¿ç”¨ `output` å…³é”®å­—å’Œ JSON æ¨¡å¼å®šä¹‰é¢„æœŸè¾“å‡ºæ ¼å¼ã€‚
* **æç¤ºæ¨¡æ¿**: ä½¿ç”¨ Jinja2 æ¨¡æ¿ï¼ˆ`{{variable_name}}`ï¼‰å°†è¾“å…¥é…ç½®æˆ–æç¤ºè®¾ç½®ä¸­çš„å˜é‡åµŒå…¥æ¶ˆæ¯ä¸­ã€‚
* **è‡ªå®šä¹‰è„šæœ¬ç±»å‹**: å…è®¸å®šä¹‰å¯é‡ç”¨çš„è„šæœ¬ç±»å‹ï¼ˆ`type: type`ï¼‰ï¼Œä»¥å®ç°ä»£ç å’Œé…ç½®çš„ç»§æ‰¿ã€‚

### [III. AI Capabilities](./lib/guide/lang-ai.md)

* **é«˜çº§ AI æ›¿æ¢:** ä½¿ç”¨åŒæ‹¬å·ï¼ˆ`[[Response]]`ï¼‰è§¦å‘ AI æ‰§è¡Œï¼Œå°†å“åº”å­˜å‚¨åœ¨å˜é‡ï¼ˆ`prompt.Response`ï¼‰ä¸­ï¼Œå¹¶åœ¨è„šæœ¬ä¸­ä½¿ç”¨ã€‚
* **AI å‚æ•°æ§åˆ¶:** é€šè¿‡åŒæ‹¬å·å†…ä¼ é€’å‚æ•°ï¼ˆä¾‹å¦‚ `[[Answer:temperature=0.7]]`ï¼‰å¾®è°ƒ AI è¡Œä¸ºã€‚
* **çº¦æŸ AI å“åº”:** é™åˆ¶ AI è¾“å‡ºä¸ºé¢„å®šä¹‰çš„é€‰é¡¹é›†ï¼ˆä¾‹å¦‚ `[[FRUITS:|Apple|Banana]]`ï¼‰ã€‚

#### [IV. æ¶ˆæ¯æ–‡æœ¬æ ¼å¼åŒ–](./lib/guide/lang-formatting.md)

è§’è‰²æ¶ˆæ¯å¯ä»¥ä½¿ç”¨ Jinja2 æ¨¡æ¿å’Œé«˜çº§æ›¿æ¢åŠŸèƒ½è¿›è¡Œæ ¼å¼åŒ–ã€‚

* **Jinja2 æ¨¡æ¿:** ä½¿ç”¨åŒå¤§æ‹¬å·ï¼ˆä¾‹å¦‚ `{{name}}`ï¼‰å¼•ç”¨è¾“å…¥é…ç½®æˆ–æç¤ºè®¾ç½®ä¸­çš„å˜é‡ã€‚
* **é«˜çº§ AI æ›¿æ¢:** å¦‚ä¸Šæ‰€è¿°ï¼Œè§¦å‘ AI æ‰§è¡Œå¹¶å­˜å‚¨å“åº”ã€‚
* **å¤–éƒ¨è„šæœ¬æ›¿æ¢:** ä½¿ç”¨ `@` ç¬¦å·è°ƒç”¨å¤–éƒ¨è„šæœ¬ï¼ˆä¾‹å¦‚ `@say_hi_script(param1=value1)`ï¼‰ã€‚
* **å†…éƒ¨æŒ‡ä»¤æ›¿æ¢:** ç±»ä¼¼åœ°è°ƒç”¨å†…éƒ¨æŒ‡ä»¤ï¼ˆä¾‹å¦‚ `@$instruction(param1=value1)`ï¼‰ã€‚
* **æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢:** ä½¿ç”¨ `/RegExp/[RegOpts]:Answer[:index_or_group_name]` å¯¹ `Answer` å˜é‡è¿›è¡ŒåŸºäºæ¨¡å¼çš„æ›¿æ¢ã€‚

### [V. Script Capabilities](./lib/guide/lang-script.md)

* **é“¾å¼è¾“å‡º:** `->` è¿ç®—ç¬¦å°†è„šæœ¬è¾“å‡ºè¿æ¥åˆ°åç»­æŒ‡ä»¤æˆ–è„šæœ¬ï¼Œåˆ›å»ºå¤æ‚çš„æµç¨‹ã€‚
* **æŒ‡ä»¤è°ƒç”¨:** ä½¿ç”¨ `$` å‰ç¼€è°ƒç”¨è„šæœ¬æŒ‡ä»¤ï¼ˆä¾‹å¦‚ `$fn: {param1:value1}` æˆ– `$fn(param1=value1)`ï¼‰ã€‚
* **æ§åˆ¶æµ:** æŒ‡ä»¤å¦‚ `$if`ã€`$pipe`ã€`$while`ã€`$match` æä¾›æ§åˆ¶æµæœºåˆ¶ã€‚
* **äº‹ä»¶é©±åŠ¨æ¶æ„:** å‡½æ•°å¦‚ `$on`ã€`$once`ã€`$emit` å’Œ `$off` å¯ç”¨åŸºäºäº‹ä»¶çš„ç¼–ç¨‹ï¼Œä½¿è„šæœ¬è¡Œä¸ºæ›´åŠ çµæ´»ã€‚
* **è„šæœ¬æ‰©å±•:**
  * `!fn` æŒ‡ä»¤å…è®¸å£°æ˜ `JavaScript`/`Python` ç­‰è¯­è¨€çš„å‡½æ•°ä»¥æ‰©å±•è„šæœ¬åŠŸèƒ½ã€‚(æ³¨ï¼š ç›®å‰åªå®ç° `JavaScript` å‡½æ•°)
  * [`import` configuration](https://github.com/offline-ai/ppe/tree/main?tab=readme-ov-file#import) å…è®¸å¯¼å…¥å¤–éƒ¨è„šæœ¬å’Œæ¨¡å—ã€‚

### Install

```bash
npm install -g @offline-ai/cli
ai brain download QuantFactory/Phi-3-mini-4k-instruct-GGUF-v2 -q Q4_0
Downloading to ~/.local/share/ai/brain
Downloading https://huggingface.co/QuantFactory/Phi-3-mini-4k-instruct-GGUF-v2/resolve/main/Phi-3-mini-4k-instruct.Q4_0.gguf... 5.61% 121977704 bytes
1. https://huggingface.co/QuantFactory/Phi-3-mini-4k-instruct-GGUF-v2/resolve/main/Phi-3-mini-4k-instruct.Q4_0.gguf
   ~/.local/share/ai/brain/phi-3-mini-4k-instruct.Q4_0.gguf
done
mkdir llamacpp
cd llamacpp
# goto https://github.com/ggerganov/llama.cpp/releases/latest download latest release
wget https://github.com/ggerganov/llama.cpp/releases/download/b3563/llama-b3563-bin-ubuntu-x64.zip
unzip llama-b3563-bin-ubuntu-x64.zip
```

å‡çº§æ›´æ–°:

```bash
# install again
npm install -g @offline-ai/cli
```

### Run

é¦–å…ˆéœ€è¦è¿è¡Œ llama.cpp server æä¾›è€…(Provider):

```bash
#run llama.cpp server
cd llamacpp/build/bin
#set -ngl 0 if no gpu
./llama-server -t 4 -c 4096 -ngl 33 -m ~/.local/share/ai/brain/phi-3-mini-4k-instruct.Q4_0.gguf
```

ç°åœ¨ä½ å¯ä»¥è¿è¡Œ AI æ™ºèƒ½ä½“è„šæœ¬(å¯ç¼–ç¨‹æç¤ºè¯)ï¼Œä¾‹å¦‚ï¼Œåœ¨`examples`ç›®å½•ä¸‹çš„`Dobby`è§’è‰²:

```bash
# è¿›å…¥äº¤äº’å¯¹è¯æ¨¡å¼
$ai run --interactive --script examples/char-dobby
```

ç›´æ¥è¿è¡Œ `translator` è„šæœ¬åº“:

```bash
# API æ¨¡å¼ï¼Œå°† TODO æ–‡ä»¶ç¿»è¯‘æˆè‹±è¯­
$ai run -f translator "{file: './TODO', target: 'English'}"

# è¿›å…¥äº¤äº’å¯¹è¯æ¨¡å¼
$ai run -if translator
```

## Usage

å®‰è£…å®¢æˆ·ç«¯:

```sh
$ npm install -g @offline-ai/cli
$ ai COMMAND
running command...
$ ai (--version)
@offline-ai/cli/0.0.1 linux-x64 node-v20.14.0
$ ai --help [COMMAND]
USAGE
  $ ai COMMAND
...
```

ä»huggingfaceä¸Šä¸‹è½½å¤§è„‘ğŸ§ (LLM).
å¦‚æœæœ¬åœ°æ— æ³•è®¿é—®huggingface, è¯·ç”¨ä»£ç†æˆ–è€…Mirror.

è¿è¡Œå¦‚ä¸‹å‘½ä»¤æ‰§è¡Œä¸‹è½½å‘½ä»¤, é€‰æ‹©ä¸€ä¸ªä¸‹è½½, æˆ–è€…è¾“å…¥æ›´å¤šæ¥å‡å°‘è„‘(æ¨¡å‹)åˆ—è¡¨.

æ³¨æ„:

* æ‰€æœ‰çš„é‡åŒ–(å‹ç¼©)å¤§è„‘ğŸ§ æ¨¡å‹å‡ä¸ºç”¨æˆ·è‡ªè¡Œä¸Šä¼ ,å› æ­¤å¹¶ä¸èƒ½ä¿è¯è¿™äº›ç”¨æˆ·è‡ªè¡Œé‡åŒ–(å‹ç¼©)çš„å¤§è„‘ğŸ§ æ¨¡å‹éƒ½èƒ½ä½¿ç”¨
* ç›®å‰å·²ç»å­˜åœ¨çš„GGUFé‡åŒ–å¤§è„‘ğŸ§ æ¨¡å‹å·²ç»ä¸Šä¸‡,æœ‰ä¸å°‘éƒ½æ˜¯é‡å¤çš„
* `ai brain list` åˆ—è¡¨ä¸­æ˜¾ç¤ºçš„å¤§è„‘åˆ—è¡¨,é»˜è®¤æ˜¯ç»è¿‡`featured`è¿‡æ»¤äº†çš„ä¸€éƒ¨åˆ†åˆ—è¡¨, å¦‚æœè¦æ˜¾ç¤ºæ‰€æœ‰çš„å¤§è„‘åˆ—è¡¨,è¯·è¾“å…¥`--no-onlyFeatured`
* `ai brain download` ä¸‹è½½æ”¯æŒè‡ªåŠ¨ç»­ä¼ 

```bash
#é»˜è®¤åˆ—å‡ºå·²ç»ä¸‹è½½çš„å¤§è„‘åˆ—è¡¨
#ç­‰äº `ai brain list --downloaded`
$ai brain
$ai brain list --downloaded
1. name: "deepseek-v2-chat", likes: 17, downloads: 1189, hf_repo: "leafspark/DeepSeek-V2-Chat-GGUF"
   * IQ2_XXS: deepseek-v2-chat.IQ2_XXS-00001-of-00003.gguf (3 files)
   * IQ3_XS: deepseek-v2-chat.IQ3_XS-00001-of-00008.gguf (8 files)
   * Q2_K: deepseek-v2-chat.Q2_K-00001-of-00005.gguf (5 files)
   * Q3_K_M: deepseek-v2-chat.Q3_K_M-00001-of-00006.gguf (6 files)
   * Q5_K_M: deepseek-v2-chat.Q5_K_M-00001-of-00008.gguf (8 files)
   * Q6_K: deepseek-v2-chat.Q6_K-00001-of-00010.gguf (10 files)
   * Q8_0: deepseek-v2-chat.Q8_0-00001-of-00012.gguf (12 files)
total: 1
#å¯ä»¥æŒ‡å®šå¤§è„‘æ¨¡å‹çš„å…³é”®å­—æœç´¢
$ai brain list qwen1.5
1. name: "codeqwen1.5-7b-chat", likes: 84, downloads: 196977, hf_repo: "Qwen/CodeQwen1.5-7B-Chat-GGUF"
   * Q2_K: codeqwen-1_5-7b-chat.Q2_K.gguf
   * Q3_K_M: codeqwen-1_5-7b-chat.Q3_K_M.gguf
   * Q4_0: codeqwen-1_5-7b-chat.Q4_0.gguf
   * Q4_K_M: codeqwen-1_5-7b-chat.Q4_K_M.gguf
   * Q5_0: codeqwen-1_5-7b-chat.Q5_0.gguf
   * Q5_K_M: codeqwen-1_5-7b-chat.Q5_K_M.gguf
   * Q6_K: codeqwen-1_5-7b-chat.Q6_K.gguf
   * Q8_0: codeqwen-1_5-7b-chat.Q8_0.gguf
2. name: "qwen1.5-72b-chat", likes: 62, downloads: 3657, hf_repo: "Qwen/Qwen1.5-72B-Chat-GGUF"
   * Q2_K: qwen1_5-72b-chat.Q2_K.gguf
   * Q3_K_M: qwen1_5-72b-chat.Q3_K_M.gguf
   * Q4_0: qwen1_5-72b-chat.Q4_0-00001-of-00002.gguf (2 files)
   * Q4_K_M: qwen1_5-72b-chat.Q4_K_M-00001-of-00002.gguf (2 files)
   * Q5_0: qwen1_5-72b-chat.Q5_0-00001-of-00002.gguf (2 files)
   * Q5_K_M: qwen1_5-72b-chat.Q5_K_M-00001-of-00002.gguf (2 files)
   * Q6_K: qwen1_5-72b-chat.Q6_K-00001-of-00002.gguf (2 files)
   * Q8_0: qwen1_5-72b-chat.Q8_0-00001-of-00003.gguf (3 files)
...
total: 35
#ä¸‹è½½å¤§è„‘, å¦‚æœè¾“å…¥çš„å…³é”®å­—å­˜åœ¨å¤šä¸ªé€‰æ‹©,ä¼šè¦æ±‚æŒ‡å®š
#llama3-8b æ˜¯å¾…æœç´¢çš„å¤§è„‘æ¨¡å‹åç§°
#`-q Q4_0` æ˜¯ä¸‹è½½çš„é‡åŒ–ç­‰çº§,å¦‚æœæ²¡æœ‰æä¾›,ä¼šæç¤ºæŒ‡å®š
#`--hubUrl` æ˜¯huggingfaceçš„é•œåƒURLåœ°å€
$ai brain download llama3-8b -q Q4_0 --hubUrl=huggingface-mirror-url-address
```

ä¸‹è½½å, è¦çŸ¥é“å¤§è„‘ä¸‹è½½çš„ä½ç½®,é€šè¿‡è¯»å–`brainDir`è®¾ç½®,å¯è§:

```bash
$ai config brainDir
{
  "brainDir": "~/.local/share/ai/brain"
}
```

ä½ å¯ä»¥åˆ›å»ºè‡ªå·±çš„é…ç½®æ–‡ä»¶åœ¨: `~/.config/ai/.ai.yaml` æˆ–è€…ç”¨ json format: `~/.config/ai/.ai.json`.

ç„¶å,ä½ éœ€è¦ä¸‹è½½å¹¶è¿è¡ŒLLMåç«¯æœåŠ¡å™¨: [llama.cpp](https://github.com/ggerganov/llama.cpp/releases/latest)

ä¸‹è½½æŒ‡ä»¤å¦‚ä¸‹:

```bash
mkdir llamacpp
cd llamacpp
wget https://github.com/ggerganov/llama.cpp/releases/download/b3091/llama-b3091-bin-ubuntu-x64.zip
unzip llama-b3091-bin-ubuntu-x64.zip
cd build/bin
#è¿è¡ŒæœåŠ¡å™¨
#`-ngl 33` means GPU layers to load, adjust it according to your GPU.
#`-c 4096` means max context length
#`-t 4` means thread count
#`-m your-brain-model.gguf` means ä½ ä¸‹è½½çš„å¤§è„‘æ¨¡å‹æ–‡ä»¶
./server -t 4 -c 4096 -ngl 33 -m ~/.local/share/ai/brain/your-brain-model.gguf
```

ç°åœ¨ä½ å¯ä»¥è¿è¡Œä½ çš„AI Agentè„šæœ¬äº†:

```bash
#ä¸ç”¨è¾“å…¥æ‰©å±•å `.ai.yaml`.
#é»˜è®¤è„šæœ¬çš„æœç´¢è·¯å¾„æ˜¯å½“å‰ç›®å½•å’Œ`~/.local/share/ai/agent`ç›®å½• . ä½ å¯ä»¥åœ¨`agentDirs`ä¸­é…ç½®, æˆ–è€…ç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®š,æ³¨æ„å‘½ä»¤è¡ŒæŒ‡å®šå°†è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®.
#`-f` means the agent file
#`-i` means è¿›å…¥äº¤äº’æ¨¡å¼, char-dobby æ˜¯ä¸€ä¸ªè§’è‰²æ™ºèƒ½ä½“è„šæœ¬,æ‰®æ¼”å“ˆåˆ©æ³¢ç‰¹ä¸­çš„dobby.
$ai run -if examples/char-dobby
Dobby: I am Dobby. Dobby is happy.
You: intro yourself pls.
Dobby: I am Dobby. I'm a brave and loyal house-elf, and I'm very proud to be a free elf. I love socks and wearing mismatched pairs.

#åœ¨å‘½ä»¤è¡Œä¸Šè¾“å…¥å†…å®¹(content)å’Œå†…å®¹çš„json schema è§„èŒƒ(output), å®ƒå°±ä¼šäº§å‡ºè¯¥å†…å®¹å¯¹åº”çš„jsonæ•°æ®.
#æ³¨æ„å…¶ç”Ÿæˆè´¨é‡å—æ‰€é€‰è„‘å­ğŸ§ çš„å½±å“.
$ai run -f examples/json '{content: "I recently purchased the Razer BlackShark V2 X Gaming Headset, and it has significantly enhanced my gaming experience. This headset offers incredible sound quality, comfort, and features that are perfect for any serious gamer. Hereâ€™s why I highly recommend it: The 7.1 surround sound feature is a game-changer. The audio quality is superb, providing a truly immersive experience. I can clearly hear directional sounds, which is crucial for competitive gaming. The depth and clarity of the sound make it feel like Iâ€™m right in the middle of the action. The 50mm drivers deliver powerful, high-quality sound. The bass is deep and punchy without being overwhelming, while the mids and highs are crisp and clear. This balance makes the headset versatile, not only for gaming but also for listening to music and watching movies.", "output":{"type":"object","properties":{"sentiment":{"type":"string","description":"Sentiment (positive or negative)"},"products":{"type":"array","items":{"type":"object","properties":{"name":{"type":"string","description":"Name of the product"},"brand":{"type":"string","description":"Company that made the product"}}},"description":"Products mentioned in the review"},"anger":{"type":"boolean","description":"Is the reviewer expressing anger?"}},"required":["sentiment","products","anger"]}}'

{
  "sentiment": "positive",
  "products": [
    {
      "name": "Razer BlackShark V2 X Gaming Headset",
      "brand": "Razer"
    }
  ],
  "anger": false
}
```

æ³¨æ„:

* é»˜è®¤è¿è¡Œåçš„å†å²è®°å½•åœ¨`~/.local/share/ai/logs/chats/[script_file_basename]/history`ç›®å½•ä¸‹. å¯ä»¥åœ¨è¿™é‡Œæ£€æŸ¥`seeds`, `temperature`ç­‰ä¿¡æ¯.
  * åœ¨äº¤äº’æ¨¡å¼ä¸‹é»˜è®¤ä¼šè‡ªåŠ¨åŠ è½½å†å²è®°å½•,å¦‚æœä¸éœ€è¦,å¯ä»¥ç”¨`--new-chat`
  * éäº¤äº’æ¨¡å¼ä¸‹ä¸ä¼šè‡ªåŠ¨åŠ è½½å†å²è®°å½•,æ¯ä¸€æ¬¡è¿è¡Œéƒ½ä¼šç”Ÿæˆæ–°çš„å†å²è®°å½•.
  * å½»åº•ç¦ç”¨å†å²è®°å½•, å¯ä»¥ç”¨`--no-chats`

**åµŒå…¥åˆ°è‡ªå·±çš„ä»£ç ä¸­(æœ¬åœ°æ–¹å¼)**:

```ts
import { AIScriptServer } from '@isdk/ai-tool-agent';

// é…ç½®ä½ çš„è„šæœ¬æœç´¢è·¯å¾„
AIScriptEx.searchPaths = ['.']
const script = AIScriptServer.load('examples/json')
// è®¾ç½®é»˜è®¤ä¸ºå¤§æ¨¡å‹æµå¼å“åº”
script.llmStream = stream

const content = "I recently purchased the Razer BlackShark V2 X Gaming Headset, and it has significantly enhanced my gaming experience. This headset offers incredible sound quality, comfort, and features that are perfect for any serious gamer. Hereâ€™s why I highly recommend it: The 7.1 surround sound feature is a game-changer. The audio quality is superb, providing a truly immersive experience. I can clearly hear directional sounds, which is crucial for competitive gaming. The depth and clarity of the sound make it feel like Iâ€™m right in the middle of the action. The 50mm drivers deliver powerful, high-quality sound. The bass is deep and punchy without being overwhelming, while the mids and highs are crisp and clear. This balance makes the headset versatile, not only for gaming but also for listening to music and watching movies."
const output = {
  "type":"object",
  "properties":{
    "sentiment":{"type":"string","description":"Sentiment (positive or negative)"},
    "products":{
      "type":"array",
      "items":{
        "type":"object",
        "properties":{
          "name":{"type":"string","description":"Name of the product"},
          "brand":{"type":"string","description":"Company that made the product"}}
      },
      "description":"Products mentioned in the review"
    },
    "anger":{"type":"boolean","description":"Is the reviewer expressing anger?"}},
  "required":["sentiment","products","anger"]
}

const result =await script.exec({content, output})
console.log(result)
// å°±å¯ä»¥çœ‹åˆ°å¤§æ¨¡å‹è¾“å‡ºçš„jsonç»“æœ:
{
  "sentiment": "positive",
  "products": [
    {
      "name": "Razer BlackShark V2 X Gaming Headset",
      "brand": "Razer"
    }
  ],
  "anger": false
}
```

å…·ä½“è„šæœ¬æŒ‡ä»¤æ‰‹å†Œå‚è§: [å¯ç¼–ç¨‹æç¤ºè¯å·¥ç¨‹è§„èŒƒ](https://github.com/offline-ai/ppe/blob/main/README.cn.md)

## Credit

* [OpenAI](https://openai.com/)
* [HuggingFace](https://huggingface.co/)
* [llama-cpp](https://github.com/ggerganov/llama.cpp)
